# ä¿®æ”¹ evaluate.py æ–‡ä»¶
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def load_model_and_evaluate(model_path, data_path):
    """
    åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹å¹¶è¯„ä¼°
    """
    # åŠ¨æ€å¯¼å…¥è‡ªå®šä¹‰å±‚
    custom_objects = {}
    
    try:
        # å°è¯•å¯¼å…¥è‡ªå®šä¹‰å±‚
        from models.vit_model import Patches, PatchEncoder
        custom_objects = {
            'Patches': Patches,
            'PatchEncoder': PatchEncoder
        }
        print("Successfully imported custom layers from models.vit_model")
    except Exception as e:
        print(f"Warning: Could not import custom layers directly: {e}")
        # å°è¯•å¦ä¸€ç§å¯¼å…¥æ–¹å¼
        try:
            import importlib.util
            vit_model_path = os.path.join(os.path.dirname(__file__), 'models', 'vit_model.py')
            if os.path.exists(vit_model_path):
                spec = importlib.util.spec_from_file_location("vit_model", vit_model_path)
                vit_model_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(vit_model_module)
                custom_objects = {
                    'Patches': vit_model_module.Patches,
                    'PatchEncoder': vit_model_module.PatchEncoder
                }
                print("Successfully imported custom layers using importlib")
            else:
                print(f"Warning: vit_model.py not found at {vit_model_path}")
        except Exception as e2:
            print(f"Warning: Could not import custom layers using importlib: {e2}")

    # ä½¿ç”¨custom_object_scopeåŠ è½½åŒ…å«è‡ªå®šä¹‰å±‚çš„æ¨¡å‹
    try:
        with tf.keras.utils.custom_object_scope(custom_objects):
            model = tf.keras.models.load_model(model_path)
    except Exception as e:
        raise Exception(f"Failed to load model: {str(e)}")
    
    print(f"Loaded model from {model_path}")
    
    # åŠ è½½æ•°æ®é›†
    from data_processing.data_loader import load_and_split_datasets
    train_ds, _, test_ds = load_and_split_datasets(data_path)
    
    # è·å–ç±»åˆ«åç§°
    class_names = None
    if hasattr(train_ds, 'class_names') and train_ds.class_names is not None:
        class_names = train_ds.class_names
    elif hasattr(test_ds, 'class_names') and test_ds.class_names is not None:
        class_names = test_ds.class_names
    else:
        # å¦‚æœæ— æ³•ä»æ•°æ®é›†è·å–ï¼Œå°è¯•ä»ç›®å½•ç»“æ„æ¨æ–­
        try:
            class_names = sorted(os.listdir(data_path))
            # è¿‡æ»¤æ‰éç›®å½•é¡¹ï¼ˆå¦‚ç³»ç»Ÿæ–‡ä»¶ï¼‰
            class_names = [name for name in class_names if os.path.isdir(os.path.join(data_path, name))]
        except:
            # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
            class_names = [f"Class_{i}" for i in range(10)]  # å‡è®¾æœ‰10ä¸ªç±»åˆ«
            print("Warning: Could not determine class names, using default names.")
    
    print(f"Using class names: {class_names}")
    
    # è¯„ä¼°æ¨¡å‹
    return evaluate_model(model, test_ds, class_names)

def evaluate_model(model, dataset, class_names):
    """
    è®¡ç®— Precision, Recall, F1-score, Accuracy å¹¶æ‰“å°
    ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    """
    y_true = []
    y_pred = []

    for images, labels in dataset:
        preds = model.predict(images, verbose=0)
        y_pred.extend(np.argmax(preds, axis=1))
        y_true.extend(np.argmax(labels.numpy(), axis=1))

    acc = accuracy_score(y_true, y_pred)
    print(f"\n Accuracy: {acc:.4f}")

    print("\n Classification Report:")
    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    plt.show()

    return acc, cm

# å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œåˆ™æ‰§è¡Œè¯„ä¼°
if __name__ == "__main__":
    # é»˜è®¤æ¨¡å‹è·¯å¾„æ˜ å°„
    model_paths = {
        "resnet": "best_resnet_model.h5",
        "vit": "best_vit_model.h5",
        "hybrid": "best_hybrid_model.h5"
    }
    
    DATA_PATH = r"E:\dataset\PotatoGPT\minidata\potato"
    
    # è·å–æ¨¡å‹ç±»å‹å‚æ•°
    if len(sys.argv) > 1:
        model_type = sys.argv[1].lower()
        if model_type in model_paths:
            MODEL_PATH = model_paths[model_type]
        else:
            MODEL_PATH = model_type  # å¦‚æœä¼ å…¥çš„æ˜¯å…·ä½“è·¯å¾„
    else:
        # é»˜è®¤ä½¿ç”¨vitæ¨¡å‹
        MODEL_PATH = "best_vit_model.h5"
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ Model file {MODEL_PATH} not found.")
        print("Available models in current directory:")
        available_models = [f for f in os.listdir('.') if f.endswith('.h5')]
        for model in available_models:
            print(f"  - {model}")
        sys.exit(1)
    
    print(f"\nğŸ” Loading model from {MODEL_PATH} and evaluating on test set...")
    try:
        load_model_and_evaluate(MODEL_PATH, DATA_PATH)
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        print("\nğŸ’¡ Tips:")
        print("1. Make sure you're running this script from the correct directory")
        print("2. Check if the model file exists")
        print("3. For ViT/Hybrid models, ensure all custom layers are properly defined")